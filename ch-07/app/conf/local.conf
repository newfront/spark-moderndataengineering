default {

  appName = "spark-event-extractor"

  spark {
    settings {
      "spark.sql.catalogImplementation" = "hive"
      "spark.sql.hive.metastore.version" = "2.3.7"
      "spark.sql.hive.metastore.jars" = "builtin"
      "spark.sql.hive.metastore.sharedPrefixes" = "com.mysql.cj.jdbc,com.mysql.jdbc,org.postgresql,com.microsoft.sqlserver,oracle.jdbc"
      "spark.sql.hive.metastore.schema.verification" = "true"
      "spark.sql.hive.metastore.schema.verification.record.version" = "true"
      "spark.sql.parquet.compression.codec" = "snappy"
      "spark.sql.parquet.mergeSchema" = "false"
      "spark.sql.parquet.filterPushdown" = "true"
      "spark.hadoop.parquet.enable.summary-metadata" = "false"
      "spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version" = "2"
      "spark.sql.hive.javax.jdo.option.ConnectionURL" = "jdbc:mysql://mysql:3306/metastore"
      "spark.sql.hive.javax.jdo.option.ConnectionDriverName" = "com.mysql.cj.jdbc.Driver"
      "spark.sql.hive.javax.jdo.option.ConnectionUserName" = "dataeng"
      "spark.sql.warehouse.dir" = "hdfs://PATH/TO/YOUR/spark/sql/warehouse"
    }
  }

}