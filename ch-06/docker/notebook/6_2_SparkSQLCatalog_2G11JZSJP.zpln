{
  "paragraphs": [
    {
      "title": "Useful Variables for versioning",
      "text": "%spark\nspark.sparkContext.getConf.getAllWithPrefix(\"spark.sql\")\nval sparkConf \u003d spark.sparkContext.getConf\nval sparkSqlWareHouse \u003d sparkConf.get(\"spark.sql.warehouse.dir\")\nval sparkSqlCatalogType \u003d sparkConf.get(\"spark.sql.catalogImplementation\")\nval hiveMetaDataVersion \u003d sparkConf.get(\"spark.sql.hive.metastore.version\")\nval hiveMetaStoreDependencies \u003d sparkConf.get(\"spark.sql.hive.metastore.jars\")",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 20:33:37.395",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34msparkConf\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.SparkConf\u001b[0m \u003d org.apache.spark.SparkConf@32a58e04\n\u001b[1m\u001b[34msparkSqlWareHouse\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d /spark/sql/warehouse/\n\u001b[1m\u001b[34msparkSqlCatalogType\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d hive\n\u001b[1m\u001b[34mhiveMetaDataVersion\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d 2.3.7\n\u001b[1m\u001b[34mhiveMetaStoreDependencies\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d builtin\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546903_1671312317",
      "id": "paragraph_1614032139535_1034844617",
      "dateCreated": "2021-03-13 22:29:06.903",
      "status": "READY"
    },
    {
      "title": "Create a Hive Enabled Spark Session",
      "text": "%spark\nimport org.apache.spark.sql._\n\n// create another SparkSession with explicit Hive Support\nval sparkSessionHive \u003d SparkSession.builder\n  .master(spark.conf.get(\"spark.master\"))\n  .config(spark.sparkContext.getConf)\n  .appName(\"hive-support\")\n  .enableHiveSupport()\n  .getOrCreate()",
      "user": "anonymous",
      "dateUpdated": "2021-03-18 00:49:37.164",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import org.apache.spark.sql._\n\u001b[1m\u001b[34msparkSessionHive\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.SparkSession\u001b[0m \u003d org.apache.spark.sql.SparkSession@5cc020d\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546903_1167453598",
      "id": "paragraph_1614033004668_108238026",
      "dateCreated": "2021-03-13 22:29:06.903",
      "dateStarted": "2021-03-18 00:49:37.182",
      "dateFinished": "2021-03-18 00:49:37.709",
      "status": "FINISHED"
    },
    {
      "title": "List the Databases through SQL DQL",
      "text": "%spark\n\nsparkSessionHive\n  .sql(\"show databases;\")\n  .show",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 22:31:58.109",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+----------------+\n|       namespace|\n+----------------+\n|coffee_co_common|\n|         default|\n+----------------+\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546903_2000036339",
      "id": "paragraph_1614033667916_1671895241",
      "dateCreated": "2021-03-13 22:29:06.903",
      "dateStarted": "2021-03-17 22:31:58.126",
      "dateFinished": "2021-03-17 22:32:06.664",
      "status": "FINISHED"
    },
    {
      "title": "List the Databases via the Catalog",
      "text": "%spark\nsparkSessionHive\n  .catalog\n  .listDatabases\n  .show(false)",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 22:32:23.812",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+----------------+----------------------------------------------------------------------------------+--------------------------------+\n|name            |description                                                                       |locationUri                     |\n+----------------+----------------------------------------------------------------------------------+--------------------------------+\n|coffee_co_common|This database stores common information regarding inventory, stores, and customers|file:/spark/sql/warehouse/common|\n|default         |Default Hive database                                                             |file:/spark/sql/warehouse       |\n+----------------+----------------------------------------------------------------------------------+--------------------------------+\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615675195339_937277653",
      "id": "paragraph_1615675195339_937277653",
      "dateCreated": "2021-03-13 22:39:55.339",
      "dateStarted": "2021-03-17 22:32:23.828",
      "dateFinished": "2021-03-17 22:32:24.175",
      "status": "FINISHED"
    },
    {
      "title": "Find the Current Database",
      "text": "%spark\nsparkSessionHive.catalog.currentDatabase",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 22:32:27.963",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mres5\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d default\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615677165087_1816080378",
      "id": "paragraph_1615677165087_1816080378",
      "dateCreated": "2021-03-13 23:12:45.087",
      "dateStarted": "2021-03-17 22:32:27.978",
      "dateFinished": "2021-03-17 22:32:28.296",
      "status": "FINISHED"
    },
    {
      "title": "Create a SQL Catalog Database",
      "text": "%spark\n\nval coffeeCoDatabaseName \u003d \"coffee_co_common\"\nval databaseDescription \u003d \"This database stores common information regarding inventory, stores, and customers\"\nval defaultWarehouse \u003d spark.catalog.getDatabase(\"default\").locationUri\nval warehousePrefix \u003d s\"$defaultWarehouse/common\"\nspark.sql(s\"\"\"\nCREATE DATABASE IF NOT EXISTS $coffeeCoDatabaseName \nCOMMENT \u0027$databaseDescription\u0027 \nLOCATION \u0027$warehousePrefix\u0027 \nWITH DBPROPERTIES(TEAM\u003d\u0027core\u0027,LEAD\u003d\u0027scott\u0027,TEAM_SLACK\u003d\u0027#help_coffee_common\u0027);\n\"\"\")",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 20:59:53.451",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mcoffeeCoDatabaseName\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d coffee_co_common\n\u001b[1m\u001b[34mdatabaseDescription\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d This database stores common information regarding inventory, stores, and customers\n\u001b[1m\u001b[34mdefaultWarehouse\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d file:/spark/sql/warehouse\n\u001b[1m\u001b[34mwarehousePrefix\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d file:/spark/sql/warehouse/common\n\u001b[1m\u001b[34mres4\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m \u003d []\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615677790269_1138712933",
      "id": "paragraph_1615677790269_1138712933",
      "dateCreated": "2021-03-13 23:23:10.269",
      "dateStarted": "2021-03-17 20:59:53.468",
      "dateFinished": "2021-03-17 20:59:54.081",
      "status": "FINISHED"
    },
    {
      "title": "View the Database Metadata Properties of our Database",
      "text": "%spark\nspark\n  .sql(\"describe database extended `coffee_co_common`\")\n  .show(truncate\u003dfalse)",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 20:59:57.715",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+-------------------------+----------------------------------------------------------------------------------+\n|database_description_item|database_description_value                                                        |\n+-------------------------+----------------------------------------------------------------------------------+\n|Database Name            |coffee_co_common                                                                  |\n|Comment                  |This database stores common information regarding inventory, stores, and customers|\n|Location                 |file:/spark/sql/warehouse/common                                                  |\n|Owner                    |zeppelin                                                                          |\n|Properties               |((TEAM,core), (TEAM_SLACK,#help_coffee_common), (LEAD,scott))                     |\n+-------------------------+----------------------------------------------------------------------------------+\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615678811282_1194685550",
      "id": "paragraph_1615678811282_1194685550",
      "dateCreated": "2021-03-13 23:40:11.282",
      "dateStarted": "2021-03-17 20:59:57.732",
      "dateFinished": "2021-03-17 20:59:58.148",
      "status": "FINISHED"
    },
    {
      "title": "SQL Describe Database",
      "text": "%sql\nDESCRIBE DATABASE EXTENDED `coffee_co_common`;",
      "user": "anonymous",
      "dateUpdated": "2021-03-13 23:41:37.847",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "database_description_item": "string",
                      "database_description_value": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/sql",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TABLE",
            "data": "database_description_item\tdatabase_description_value\nDatabase Name\tcoffee_co_common\nComment\tThis database stores common information regarding inventory, stores, and customers\nLocation\tfile:/spark/sql/warehouse/common\nOwner\tzeppelin\nProperties\t((TEAM,core), (TEAM_SLACK,#help_coffee_common), (LEAD,scott))\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615678770942_297795852",
      "id": "paragraph_1615678770942_297795852",
      "dateCreated": "2021-03-13 23:39:30.943",
      "dateStarted": "2021-03-13 23:39:53.205",
      "dateFinished": "2021-03-13 23:39:53.327",
      "status": "FINISHED"
    },
    {
      "title": "View the Current Spark SQL Catalog Implementation",
      "text": "%spark\nsparkSessionHive.conf.get(\"spark.sql.catalogImplementation\")",
      "user": "anonymous",
      "dateUpdated": "2021-03-13 23:47:47.546",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mres3\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d hive\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546903_1103471428",
      "id": "paragraph_1614033688152_324946610",
      "dateCreated": "2021-03-13 22:29:06.903",
      "status": "READY"
    },
    {
      "title": "Importing Tables using JDBC",
      "text": "%spark\nval jdbcDriver \u003d spark.conf.get(\"spark.jdbc.driver.class\", \"org.mariadb.jdbc.Driver\")\nval dbHost     \u003d spark.conf.get(\"spark.jdbc.host\",\"mysql\")\nval dbPort     \u003d spark.conf.get(\"spark.jdbc.port\", \"3306\")\nval defaultDb  \u003d spark.conf.get(\"spark.jdbc.default.db\", \"default\")\nval dbTable    \u003d spark.conf.get(\"spark.jdbc.table\", \"bettercustomers\")\nval dbUser     \u003d spark.conf.get(\"spark.jdbc.user\", \"dataeng\")\nval dbPass     \u003d spark.conf.get(\"spark.jdbc.password\", \"dataengineering_user\")\n\nval connectionUrl \u003d s\"jdbc:mysql://$dbHost:$dbPort/$defaultDb\"\n\nval betterCustomers \u003d sparkSessionHive.read\n  .format(\"jdbc\")\n  .option(\"url\", connectionUrl)\n  .option(\"driver\", jdbcDriver)\n  .option(\"dbtable\", \"bettercustomers\")\n  .option(\"user\", dbUser)\n  .option(\"password\", dbPass)\n  .load()\n\nbetterCustomers.createOrReplaceTempView(\"customers\")\n\n",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 21:00:09.528",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mjdbcDriver\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d org.mariadb.jdbc.Driver\n\u001b[1m\u001b[34mdbHost\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d mysql\n\u001b[1m\u001b[34mdbPort\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d 3306\n\u001b[1m\u001b[34mdefaultDb\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d default\n\u001b[1m\u001b[34mdbTable\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d bettercustomers\n\u001b[1m\u001b[34mdbUser\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d dataeng\n\u001b[1m\u001b[34mdbPass\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d dataengineering_user\n\u001b[1m\u001b[34mconnectionUrl\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d jdbc:mysql://mysql:3306/default\n\u001b[1m\u001b[34mbetterCustomers\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m \u003d [id: int, created: timestamp ... 4 more fields]\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546904_1407765611",
      "id": "paragraph_1614131983761_1528819603",
      "dateCreated": "2021-03-13 22:29:06.904",
      "dateStarted": "2021-03-17 21:00:09.542",
      "dateFinished": "2021-03-17 21:00:10.259",
      "status": "FINISHED"
    },
    {
      "title": "View the MySQL customers",
      "text": "%sql\nselect * from customers;",
      "user": "anonymous",
      "dateUpdated": "2021-03-13 23:52:00.434",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "id": "string",
                      "created": "string",
                      "updated": "string",
                      "first_name": "string",
                      "last_name": "string",
                      "email": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TABLE",
            "data": "id\tcreated\tupdated\tfirst_name\tlast_name\temail\n1\t2021-02-16 00:16:06.0\t2021-03-13 21:10:28.0\tScott\tHaines\tscott@coffeeco.com\n2\t2021-02-16 00:16:06.0\t2021-03-13 21:10:28.0\tJohn\tHamm\tjohn.hamm@acme.com\n3\t2021-02-16 00:16:06.0\t2021-03-13 21:10:28.0\tMilo\tHaines\tmhaines@coffeeco.com\n4\t2021-02-21 21:00:00.0\t2021-03-13 21:10:28.0\tPenny\tHaines\tpenny@coffeeco.com\n5\t2021-02-21 22:00:00.0\t2021-03-13 21:10:28.0\tCloud\tFast\tcloud.fast@acme.com\n6\t2021-02-21 23:00:00.0\t2021-03-13 21:10:28.0\tMarshal\tHaines\tpaws@coffeeco.com\n7\t2021-02-24 09:00:00.0\t2021-03-13 21:10:28.0\tWillow\tHaines\twillow@coffeeco.com\n8\t2021-02-24 09:00:00.0\t2021-03-13 21:10:28.0\tClover\tHaines\tpup@coffeeco.com\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546904_786444372",
      "id": "paragraph_1614291836922_985514881",
      "dateCreated": "2021-03-13 22:29:06.904",
      "status": "READY"
    },
    {
      "text": "%spark\nsparkSessionHive.catalog.listTables.show\n",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 21:00:15.358",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+---------+--------+-----------+---------+-----------+\n|     name|database|description|tableType|isTemporary|\n+---------+--------+-----------+---------+-----------+\n|customers| default|       null|  MANAGED|      false|\n|customers|    null|       null|TEMPORARY|       true|\n+---------+--------+-----------+---------+-----------+\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546904_1466047916",
      "id": "paragraph_1615670683362_390169303",
      "dateCreated": "2021-03-13 22:29:06.904",
      "dateStarted": "2021-03-17 21:00:15.372",
      "dateFinished": "2021-03-17 21:00:16.395",
      "status": "FINISHED"
    },
    {
      "title": "Save JDBC Data into the Data Lake",
      "text": "%spark\n\nval coffeeCoDatabaseName \u003d \"coffee_co_common\"\nsparkSessionHive.catalog\n  .setCurrentDatabase(coffeeCoDatabaseName)\nbetterCustomers\n  .write\n  .mode(\"overwrite\")\n  .saveAsTable(\"customers\")",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 21:00:25.077",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mcoffeeCoDatabaseName\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d coffee_co_common\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://zeppelin:4040/jobs/job?id\u003d0"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546905_1744766306",
      "id": "paragraph_1614132682783_1946545629",
      "dateCreated": "2021-03-13 22:29:06.905",
      "dateStarted": "2021-03-17 21:00:25.093",
      "dateFinished": "2021-03-17 21:00:29.537",
      "status": "FINISHED"
    },
    {
      "text": "%spark\nsparkSessionHive.catalog.listTables.show",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 21:00:37.401",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+---------+----------------+-----------+---------+-----------+\n|     name|        database|description|tableType|isTemporary|\n+---------+----------------+-----------+---------+-----------+\n|customers|coffee_co_common|       null|  MANAGED|      false|\n|customers|            null|       null|TEMPORARY|       true|\n+---------+----------------+-----------+---------+-----------+\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615681148562_253162310",
      "id": "paragraph_1615681148562_253162310",
      "dateCreated": "2021-03-14 00:19:08.562",
      "dateStarted": "2021-03-17 21:00:37.417",
      "dateFinished": "2021-03-17 21:00:37.775",
      "status": "FINISHED"
    },
    {
      "title": "Using the SharedState to list external tables",
      "text": "%spark\nsparkSessionHive.sharedState.externalCatalog.listTables(\"coffee_co_common\")",
      "user": "anonymous",
      "dateUpdated": "2021-03-14 21:58:28.239",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mres80\u001b[0m: \u001b[1m\u001b[32mSeq[String]\u001b[0m \u003d Buffer(customers)\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546904_907161298",
      "id": "paragraph_1614131951560_589500840",
      "dateCreated": "2021-03-13 22:29:06.904",
      "dateStarted": "2021-03-14 21:58:28.251",
      "dateFinished": "2021-03-14 21:58:28.434",
      "status": "FINISHED"
    },
    {
      "text": "%md\n# Databases and Tables in the Hive Metastore\n\n## Exploring the MetaData Stored in MySQL\n\n1. Open up a new terminal session, or tab. \n2. Open a new bash session on the mysql container.\n3. Login into the mysql cli\n\n~~~\ndocker exec -it mysql bash\nmysql -u dataeng -p\n~~~\n\n### Explore the Hive Metastore Table Data\nFrom the mysql cli.\n~~~\nmysql\u003e use metastore;\n~~~\n\n### Databases\nThe DBS table schema.\n~~~\nmysql\u003e describe DBS;\n~~~\n~~~\n+-----------------+---------------+------+-----+---------+-------+\n| Field           | Type          | Null | Key | Default | Extra |\n+-----------------+---------------+------+-----+---------+-------+\n| DB_ID           | bigint        | NO   | PRI | NULL    |       |\n| DESC            | varchar(4000) | YES  |     | NULL    |       |\n| DB_LOCATION_URI | varchar(4000) | NO   |     | NULL    |       |\n| NAME            | varchar(128)  | YES  | UNI | NULL    |       |\n| OWNER_NAME      | varchar(128)  | YES  |     | NULL    |       |\n| OWNER_TYPE      | varchar(10)   | YES  |     | NULL    |       |\n+-----------------+---------------+------+-----+---------+-------+\n~~~\n\nFind the` coffee_co_common` Database\n~~~\nmysql\u003e select * from DBS where NAME \u003d \u0027coffee_co_common\u0027;\n~~~\n~~~\n+-------+------------------------------------------------------------------------------------+-------------+\n| DB_ID | DESC                     | DB_LOCATION_URI          | NAME             | OWNER_NAME | OWNER_TYPE |\n+-------+------------------------------------------------------------------------------------+-------------+\n|     2 | This database stores ... | file:...warehouse/common | coffee_co_common | zeppelin   | USER       |\n+-------+------------------------------------------------------------------------------------+-------------+\n~~~\n\n### Tables and Table Properties\n\nThe `TBLS` schema.\n~~~\nmysql\u003e describe TBLS;\n~~~\n~~~\n+--------------------+--------------+------+-----+---------+-------+\n| Field              | Type         | Null | Key | Default | Extra |\n+--------------------+--------------+------+-----+---------+-------+\n| TBL_ID             | bigint       | NO   | PRI | NULL    |       |\n| CREATE_TIME        | int          | NO   |     | NULL    |       |\n| DB_ID              | bigint       | YES  | MUL | NULL    |       |\n| LAST_ACCESS_TIME   | int          | NO   |     | NULL    |       |\n| OWNER              | varchar(767) | YES  |     | NULL    |       |\n| RETENTION          | int          | NO   |     | NULL    |       |\n| SD_ID              | bigint       | YES  | MUL | NULL    |       |\n| TBL_NAME           | varchar(256) | YES  | MUL | NULL    |       |\n| TBL_TYPE           | varchar(128) | YES  |     | NULL    |       |\n| VIEW_EXPANDED_TEXT | mediumtext   | YES  |     | NULL    |       |\n| VIEW_ORIGINAL_TEXT | mediumtext   | YES  |     | NULL    |       |\n| IS_REWRITE_ENABLED | bit(1)       | NO   |     | b\u00270\u0027    |       |\n+--------------------+--------------+------+-----+---------+-------+\n~~~\n\n~~~\nmysql\u003e select TBL_ID,TBL_TYPE,TBL_NAME,SD_ID from TBLS where DB_ID \u003d 2;\n~~~\n~~~\n+--------+---------------+-----------+-------+\n| TBL_ID | TBL_TYPE      | TBL_NAME  | SD_ID |\n+--------+---------------+-----------+-------+\n|      4 | MANAGED_TABLE | customers |     4 |\n+--------+---------------+-----------+-------+\n~~~\n\n#### Table Parameters aka Table Properties\n~~~\nmysql\u003e describe TABLE_PARAMS;\n~~~\n~~~\n+-------------+--------------+------+-----+---------+-------+\n| Field       | Type         | Null | Key | Default | Extra |\n+-------------+--------------+------+-----+---------+-------+\n| TBL_ID      | bigint       | NO   | PRI | NULL    |       |\n| PARAM_KEY   | varchar(256) | NO   | PRI | NULL    |       |\n| PARAM_VALUE | mediumtext   | YES  |     | NULL    |       |\n+-------------+--------------+------+-----+---------+-------+\n~~~\n\n~~~\nmysql\u003e select * from TABLE_PARAMS where TBL_ID \u003d 4;\n~~~\n\n~~~\n+--------+-----------------------------------+----------------------+\n| TBL_ID | PARAM_KEY                         | PARAM_VALUE          |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n+--------+-----------------------------------+----------------------+\n|      4 | comment                           | Loyal patrons of...  |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n|      4 | numFiles                          | 1                    |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n|      4 | spark.sql.create.version          | 3.1.1                |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n|      4 | spark.sql.partitionProvider       | filesystem           |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n|      4 | spark.sql.sources.provider        | parquet              |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n|      4 | spark.sql.sources.schema.numParts | 1                    |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n|      4 | spark.sql.sources.schema.part.0   | {\"type\":\"struct\"...} |\n|      4 | totalSize                         | 1896                 |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n|      4 | transient_lastDdlTime             | 1615756742           |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n+--------+-----------------------------------+----------------------+\n~~~\n\n### Viewing Column Metadata\nFinding more information about the Column Data Types and Any Comments or Column Descriptions.\n~~~\nmysql\u003e select * from COLUMNS_V2;\n+-------+-----------------------------------+-------------+-----------+-------------+\n| CD_ID | COMMENT                           | COLUMN_NAME | TYPE_NAME | INTEGER_IDX |\n+-------+-----------------------------------+-------------+-----------+-------------+\n|     4 | NULL                              | created     | timestamp |           1 |\n|     4 | Not to be used for Marketing      | email       | string    |           5 |\n|     4 | Our Friendly Customers First Name | first_name  | string    |           3 |\n|     4 | NULL                              | id          | string    |           0 |\n|     4 | Our Customers Last Name           | last_name   | string    |           4 |\n|     4 | NULL                              | updated     | timestamp |           2 |\n+-------+-----------------------------------+-------------+-----------+-------------+\n6 rows in set (0.00 sec)\n~~~\n\n### Viewing Table Location Paths\nGet the Location of the Warehouse for the Table\n~~~\nSELECT DISTINCT B.TBL_ID AS TABLE_ID, \nB.TBL_NAME AS TABLE_NAME, \nA.LOCATION AS HDFS_PATH\nFROM SDS A, TBLS B\nWHERE A.SD_ID\u003dB.SD_ID;\n~~~\n~~~\n+----------+------------+--------------------------------------------+\n| TABLE_ID | TABLE_NAME | HDFS_PATH                                  |\n+----------+------------+--------------------------------------------+\n|        4 | customers  | file:/spark/sql/warehouse/common/customers |\n+----------+------------+--------------------------------------------+\n~~~",
      "user": "anonymous",
      "dateUpdated": "2021-03-14 22:08:39.218",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003eDatabases and Tables in the Hive Metastore\u003c/h1\u003e\n\u003ch2\u003eExploring the MetaData Stored in MySQL\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eOpen up a new terminal session, or tab.\u003c/li\u003e\n\u003cli\u003eOpen a new bash session on the mysql container.\u003c/li\u003e\n\u003cli\u003eLogin into the mysql cli\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode\u003edocker exec -it mysql bash\nmysql -u dataeng -p\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eExplore the Hive Metastore Table Data\u003c/h3\u003e\n\u003cp\u003eFrom the mysql cli.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emysql\u0026gt; use metastore;\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eDatabases\u003c/h3\u003e\n\u003cp\u003eThe DBS table schema.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emysql\u0026gt; describe DBS;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e+-----------------+---------------+------+-----+---------+-------+\n| Field           | Type          | Null | Key | Default | Extra |\n+-----------------+---------------+------+-----+---------+-------+\n| DB_ID           | bigint        | NO   | PRI | NULL    |       |\n| DESC            | varchar(4000) | YES  |     | NULL    |       |\n| DB_LOCATION_URI | varchar(4000) | NO   |     | NULL    |       |\n| NAME            | varchar(128)  | YES  | UNI | NULL    |       |\n| OWNER_NAME      | varchar(128)  | YES  |     | NULL    |       |\n| OWNER_TYPE      | varchar(10)   | YES  |     | NULL    |       |\n+-----------------+---------------+------+-----+---------+-------+\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eFind the\u003ccode\u003ecoffee_co_common\u003c/code\u003e Database\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emysql\u0026gt; select * from DBS where NAME \u003d \u0027coffee_co_common\u0027;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e+-------+------------------------------------------------------------------------------------+-------------+\n| DB_ID | DESC                     | DB_LOCATION_URI          | NAME             | OWNER_NAME | OWNER_TYPE |\n+-------+------------------------------------------------------------------------------------+-------------+\n|     2 | This database stores ... | file:...warehouse/common | coffee_co_common | zeppelin   | USER       |\n+-------+------------------------------------------------------------------------------------+-------------+\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eTables and Table Properties\u003c/h3\u003e\n\u003cp\u003eThe \u003ccode\u003eTBLS\u003c/code\u003e schema.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emysql\u0026gt; describe TBLS;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e+--------------------+--------------+------+-----+---------+-------+\n| Field              | Type         | Null | Key | Default | Extra |\n+--------------------+--------------+------+-----+---------+-------+\n| TBL_ID             | bigint       | NO   | PRI | NULL    |       |\n| CREATE_TIME        | int          | NO   |     | NULL    |       |\n| DB_ID              | bigint       | YES  | MUL | NULL    |       |\n| LAST_ACCESS_TIME   | int          | NO   |     | NULL    |       |\n| OWNER              | varchar(767) | YES  |     | NULL    |       |\n| RETENTION          | int          | NO   |     | NULL    |       |\n| SD_ID              | bigint       | YES  | MUL | NULL    |       |\n| TBL_NAME           | varchar(256) | YES  | MUL | NULL    |       |\n| TBL_TYPE           | varchar(128) | YES  |     | NULL    |       |\n| VIEW_EXPANDED_TEXT | mediumtext   | YES  |     | NULL    |       |\n| VIEW_ORIGINAL_TEXT | mediumtext   | YES  |     | NULL    |       |\n| IS_REWRITE_ENABLED | bit(1)       | NO   |     | b\u00270\u0027    |       |\n+--------------------+--------------+------+-----+---------+-------+\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003emysql\u0026gt; select TBL_ID,TBL_TYPE,TBL_NAME,SD_ID from TBLS where DB_ID \u003d 2;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e+--------+---------------+-----------+-------+\n| TBL_ID | TBL_TYPE      | TBL_NAME  | SD_ID |\n+--------+---------------+-----------+-------+\n|      4 | MANAGED_TABLE | customers |     4 |\n+--------+---------------+-----------+-------+\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4\u003eTable Parameters aka Table Properties\u003c/h4\u003e\n\u003cpre\u003e\u003ccode\u003emysql\u0026gt; describe TABLE_PARAMS;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e+-------------+--------------+------+-----+---------+-------+\n| Field       | Type         | Null | Key | Default | Extra |\n+-------------+--------------+------+-----+---------+-------+\n| TBL_ID      | bigint       | NO   | PRI | NULL    |       |\n| PARAM_KEY   | varchar(256) | NO   | PRI | NULL    |       |\n| PARAM_VALUE | mediumtext   | YES  |     | NULL    |       |\n+-------------+--------------+------+-----+---------+-------+\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003emysql\u0026gt; select * from TABLE_PARAMS where TBL_ID \u003d 4;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e+--------+-----------------------------------+----------------------+\n| TBL_ID | PARAM_KEY                         | PARAM_VALUE          |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n+--------+-----------------------------------+----------------------+\n|      4 | comment                           | Loyal patrons of...  |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n|      4 | numFiles                          | 1                    |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n|      4 | spark.sql.create.version          | 3.1.1                |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n|      4 | spark.sql.partitionProvider       | filesystem           |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n|      4 | spark.sql.sources.provider        | parquet              |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n|      4 | spark.sql.sources.schema.numParts | 1                    |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n|      4 | spark.sql.sources.schema.part.0   | {\u0026quot;type\u0026quot;:\u0026quot;struct\u0026quot;...} |\n|      4 | totalSize                         | 1896                 |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n|      4 | transient_lastDdlTime             | 1615756742           |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n+--------+-----------------------------------+----------------------+\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eViewing Column Metadata\u003c/h3\u003e\n\u003cp\u003eFinding more information about the Column Data Types and Any Comments or Column Descriptions.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emysql\u0026gt; select * from COLUMNS_V2;\n+-------+-----------------------------------+-------------+-----------+-------------+\n| CD_ID | COMMENT                           | COLUMN_NAME | TYPE_NAME | INTEGER_IDX |\n+-------+-----------------------------------+-------------+-----------+-------------+\n|     4 | NULL                              | created     | timestamp |           1 |\n|     4 | Not to be used for Marketing      | email       | string    |           5 |\n|     4 | Our Friendly Customers First Name | first_name  | string    |           3 |\n|     4 | NULL                              | id          | string    |           0 |\n|     4 | Our Customers Last Name           | last_name   | string    |           4 |\n|     4 | NULL                              | updated     | timestamp |           2 |\n+-------+-----------------------------------+-------------+-----------+-------------+\n6 rows in set (0.00 sec)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eViewing Table Location Paths\u003c/h3\u003e\n\u003cp\u003eGet the Location of the Warehouse for the Table\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eSELECT DISTINCT B.TBL_ID AS TABLE_ID, \nB.TBL_NAME AS TABLE_NAME, \nA.LOCATION AS HDFS_PATH\nFROM SDS A, TBLS B\nWHERE A.SD_ID\u003dB.SD_ID;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e+----------+------------+--------------------------------------------+\n| TABLE_ID | TABLE_NAME | HDFS_PATH                                  |\n+----------+------------+--------------------------------------------+\n|        4 | customers  | file:/spark/sql/warehouse/common/customers |\n+----------+------------+--------------------------------------------+\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546905_686710304",
      "id": "paragraph_1614132843869_1058875845",
      "dateCreated": "2021-03-13 22:29:06.905",
      "dateStarted": "2021-03-14 22:08:39.219",
      "dateFinished": "2021-03-14 22:08:39.235",
      "status": "FINISHED"
    },
    {
      "text": "%md\n## Loading a Table using the Spark SQL Catalog\n\n~~~\nspark.table(\"{TABLE_NAME}\")\n~~~\n\nFor example. We will load the `customers` table we just stored into our Data Lake below.",
      "user": "anonymous",
      "dateUpdated": "2021-03-14 21:43:29.174",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eLoading a Table using the Spark SQL Catalog\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003espark.table(\u0026quot;{TABLE_NAME}\u0026quot;)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eFor example. We will load the \u003ccode\u003ecustomers\u003c/code\u003e table we just stored into our Data Lake below.\u003c/p\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546905_223740401",
      "id": "paragraph_1614134497516_278573766",
      "dateCreated": "2021-03-13 22:29:06.905",
      "dateStarted": "2021-03-14 21:43:29.175",
      "dateFinished": "2021-03-14 21:43:29.190",
      "status": "FINISHED"
    },
    {
      "title": "Loading Tables",
      "text": "%spark\nval dbName \u003d \"coffee_co_common\"\nsparkSessionHive\n  .catalog\n  .setCurrentDatabase(dbName)\n\nsparkSessionHive\n  .table(\"customers\")\n  .show()",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 22:32:51.933",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+---+-------------------+-------------------+----------+---------+--------------------+\n| id|            created|            updated|first_name|last_name|               email|\n+---+-------------------+-------------------+----------+---------+--------------------+\n|  1|2021-02-16 00:16:06|2021-03-13 21:10:28|     Scott|   Haines|  scott@coffeeco.com|\n|  2|2021-02-16 00:16:06|2021-03-13 21:10:28|      John|     Hamm|  john.hamm@acme.com|\n|  3|2021-02-16 00:16:06|2021-03-13 21:10:28|      Milo|   Haines|mhaines@coffeeco.com|\n|  4|2021-02-21 21:00:00|2021-03-13 21:10:28|     Penny|   Haines|  penny@coffeeco.com|\n|  5|2021-02-21 22:00:00|2021-03-13 21:10:28|     Cloud|     Fast| cloud.fast@acme.com|\n|  6|2021-02-21 23:00:00|2021-03-13 21:10:28|   Marshal|   Haines|   paws@coffeeco.com|\n|  7|2021-02-24 09:00:00|2021-03-13 21:10:28|    Willow|   Haines| willow@coffeeco.com|\n|  8|2021-02-24 09:00:00|2021-03-13 21:10:28|    Clover|   Haines|    pup@coffeeco.com|\n+---+-------------------+-------------------+----------+---------+--------------------+\n\n\u001b[1m\u001b[34mdbName\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d coffee_co_common\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://zeppelin:4040/jobs/job?id\u003d0"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546905_1823081747",
      "id": "paragraph_1614134306083_1042728519",
      "dateCreated": "2021-03-13 22:29:06.905",
      "dateStarted": "2021-03-17 22:32:51.954",
      "dateFinished": "2021-03-17 22:32:55.955",
      "status": "FINISHED"
    },
    {
      "title": "Accessing the Hive Metastore Table Parameters from Spark SQL",
      "text": "%spark\n\nval details \u003d sparkSessionHive.read\n  .format(\"jdbc\")\n  .option(\"url\", \"jdbc:mysql://mysql:3306/default\")\n  .option(\"driver\", \"org.mariadb.jdbc.Driver\")\n  .option(\"query\", \"select * from metastore.`TABLE_PARAMS`\")\n  .option(\"user\", \"dataeng\")\n  .option(\"password\", \"dataengineering_user\")\n  .load()\n\ndetails.createOrReplaceTempView(\"metadata\")\n\n\n",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 21:00:54.409",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mdetails\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m \u003d [TBL_ID: bigint, PARAM_KEY: string ... 1 more field]\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546905_972433833",
      "id": "paragraph_1614296517483_1395430639",
      "dateCreated": "2021-03-13 22:29:06.905",
      "dateStarted": "2021-03-17 21:00:54.421",
      "dateFinished": "2021-03-17 21:00:54.722",
      "status": "FINISHED"
    },
    {
      "title": "Interactively Query the Table Metadata",
      "text": "%sql\nselect * from metadata;",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 21:00:57.148",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 354.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "TBL_ID": "string",
                      "PARAM_KEY": "string",
                      "PARAM_VALUE": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TABLE",
            "data": "TBL_ID\tPARAM_KEY\tPARAM_VALUE\n3\tnumFiles\t1\n3\tspark.sql.create.version\t3.1.1\n3\tspark.sql.sources.provider\tparquet\n3\tspark.sql.sources.schema.numParts\t1\n3\tspark.sql.sources.schema.part.0\t{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"created\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{}},{\"name\":\"updated\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{}},{\"name\":\"first_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"last_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"email\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}\n3\ttotalSize\t1896\n3\ttransient_lastDdlTime\t1615680720\n26\tnumFiles\t1\n26\tspark.sql.create.version\t3.1.1\n26\tspark.sql.sources.provider\tparquet\n26\tspark.sql.sources.schema.numParts\t1\n26\tspark.sql.sources.schema.part.0\t{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"created\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{}},{\"name\":\"updated\",\"type\":\"timestamp\",\"nullable\":true,\"metadata\":{}},{\"name\":\"first_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"last_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"email\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}\n26\ttotalSize\t1896\n26\ttransient_lastDdlTime\t1616014829\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://zeppelin:4040/jobs/job?id\u003d2"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546905_657126648",
      "id": "paragraph_1614298421314_1321239832",
      "dateCreated": "2021-03-13 22:29:06.905",
      "dateStarted": "2021-03-17 21:00:57.163",
      "dateFinished": "2021-03-17 21:00:57.400",
      "status": "FINISHED"
    },
    {
      "text": "%md\n## Table and Column Level Annotations\n\n### Table Level Comments\n~~~sql\nALTER TABLE customers SET TBLPROPERTIES (\u0027comment\u0027 \u003d \u0027Production Customers Data\u0027, \u0027active\u0027 \u003d \u0027true\u0027)\n~~~\n\n### Column Level Comments\n~~~sql\nALTER TABLE customers ALTER COLUMN first_name COMMENT \"Customers First Name on File\";\n~~~\n\n[Useful Databricks Reference](https://docs.databricks.com/spark/latest/spark-sql/language-manual/sql-ref-syntax-ddl-alter-table.html)",
      "user": "anonymous",
      "dateUpdated": "2021-03-14 22:43:27.595",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eTable and Column Level Annotations\u003c/h2\u003e\n\u003ch3\u003eTable Level Comments\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class\u003d\"language-sql\"\u003eALTER TABLE customers SET TBLPROPERTIES (\u0027comment\u0027 \u003d \u0027Production Customers Data\u0027, \u0027active\u0027 \u003d \u0027true\u0027)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eColumn Level Comments\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class\u003d\"language-sql\"\u003eALTER TABLE customers ALTER COLUMN first_name COMMENT \u0026quot;Customers First Name on File\u0026quot;;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ca href\u003d\"https://docs.databricks.com/spark/latest/spark-sql/language-manual/sql-ref-syntax-ddl-alter-table.html\"\u003eUseful Databricks Reference\u003c/a\u003e\u003c/p\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546906_894791775",
      "id": "paragraph_1614133841320_702960978",
      "dateCreated": "2021-03-13 22:29:06.906",
      "dateStarted": "2021-03-14 22:43:27.595",
      "dateFinished": "2021-03-14 22:43:27.603",
      "status": "FINISHED"
    },
    {
      "title": "Annotations: Table Level Description",
      "text": "%sql\nALTER TABLE customers SET TBLPROPERTIES (\u0027comment\u0027 \u003d \u0027Production Customers Data\u0027, \u0027active\u0027 \u003d \u0027true\u0027)",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 21:01:05.325",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546906_777262633",
      "id": "paragraph_1614133174215_1964198111",
      "dateCreated": "2021-03-13 22:29:06.906",
      "dateStarted": "2021-03-17 21:01:05.341",
      "dateFinished": "2021-03-17 21:01:05.715",
      "status": "FINISHED"
    },
    {
      "text": "%spark\nsparkSessionHive.sql(\n\"\"\"\nALTER TABLE customers \nSET TBLPROPERTIES (\n  \u0027comment\u0027 \u003d \u0027Production Customers Data\u0027,\n  \u0027active\u0027 \u003d \u0027true\u0027\n)\n\"\"\")\n",
      "user": "anonymous",
      "dateUpdated": "2021-03-14 22:45:40.911",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mres90\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m \u003d []\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615761932326_830639093",
      "id": "paragraph_1615761932326_830639093",
      "dateCreated": "2021-03-14 22:45:32.326",
      "dateStarted": "2021-03-14 22:45:40.922",
      "dateFinished": "2021-03-14 22:45:41.355",
      "status": "FINISHED"
    },
    {
      "text": "%spark\nsparkSessionHive\n  .catalog\n  .listTables\n  .where($\"database\".equalTo(\"coffee_co_common\"))\n  .select($\"name\", $\"description\", $\"tableType\")\n  .show(truncate\u003dfalse)\n",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 21:01:10.458",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+---------+-------------------------+---------+\n|name     |description              |tableType|\n+---------+-------------------------+---------+\n|customers|Production Customers Data|MANAGED  |\n+---------+-------------------------+---------+\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546906_1674812491",
      "id": "paragraph_1614133216111_1284185910",
      "dateCreated": "2021-03-13 22:29:06.906",
      "dateStarted": "2021-03-17 21:01:10.473",
      "dateFinished": "2021-03-17 21:01:11.187",
      "status": "FINISHED"
    },
    {
      "title": "Annotations: Column Level Descriptions (comments)",
      "text": "%sql\nuse coffee_co_common;\nALTER TABLE customers ALTER COLUMN id \n  COMMENT \"Unique identifier for our Customer.\";\nALTER TABLE customers ALTER COLUMN created \n  COMMENT \"timestamp when the account became active\";\nALTER TABLE customers ALTER COLUMN updated\n  COMMENT \"timestamp when this record last changed\";\nALTER TABLE customers ALTER COLUMN first_name \n  COMMENT \"The first name on the account\";\nALTER TABLE customers ALTER COLUMN last_name \n  COMMENT \"The last name on the account\";\nALTER TABLE customers ALTER COLUMN email \n  COMMENT \"customers email on file. Unique Constraint. Not to be used for Marketing\";\n",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 21:01:13.705",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546906_1710881191",
      "id": "paragraph_1614133599477_2107221871",
      "dateCreated": "2021-03-13 22:29:06.906",
      "dateStarted": "2021-03-17 21:01:13.717",
      "dateFinished": "2021-03-17 21:01:15.005",
      "status": "FINISHED"
    },
    {
      "text": "%spark\nval dbName \u003d \"coffee_co_common\"\nval tableName \u003d \"customers\"\n\nsparkSessionHive\n  .catalog\n  //.listColumns(tableName)\n  .listColumns(dbName, tableName)\n  .select($\"name\", $\"description\", $\"dataType\")\n  .show()\n",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 21:01:17.594",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+----------+--------------------+---------+\n|      name|         description| dataType|\n+----------+--------------------+---------+\n|        id|Unique identifier...|      int|\n|   created|timestamp when th...|timestamp|\n|   updated|timestamp when th...|timestamp|\n|first_name|The first name on...|   string|\n| last_name|The last name on ...|   string|\n|     email|customers email o...|   string|\n+----------+--------------------+---------+\n\n\u001b[1m\u001b[34mdbName\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d coffee_co_common\n\u001b[1m\u001b[34mtableName\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d customers\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615763190484_892545124",
      "id": "paragraph_1615763190484_892545124",
      "dateCreated": "2021-03-14 23:06:30.484",
      "dateStarted": "2021-03-17 21:01:17.617",
      "dateFinished": "2021-03-17 21:01:18.080",
      "status": "FINISHED"
    },
    {
      "title": "Using an Extended Describe on the customers Table",
      "text": "%spark\nsparkSessionHive\n  .sql(\"describe extended coffee_co_common.`customers`\")\n  .show(40)",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 21:01:22.462",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+--------------------+--------------------+--------------------+\n|            col_name|           data_type|             comment|\n+--------------------+--------------------+--------------------+\n|                  id|                 int|Unique identifier...|\n|             created|           timestamp|timestamp when th...|\n|             updated|           timestamp|timestamp when th...|\n|          first_name|              string|The first name on...|\n|           last_name|              string|The last name on ...|\n|               email|              string|customers email o...|\n|                    |                    |                    |\n|# Detailed Table ...|                    |                    |\n|            Database|    coffee_co_common|                    |\n|               Table|           customers|                    |\n|               Owner|            zeppelin|                    |\n|        Created Time|Wed Mar 17 21:00:...|                    |\n|         Last Access|             UNKNOWN|                    |\n|          Created By|         Spark 3.1.1|                    |\n|                Type|             MANAGED|                    |\n|            Provider|             parquet|                    |\n|             Comment|Production Custom...|                    |\n|    Table Properties|       [active\u003dtrue]|                    |\n|          Statistics|          1896 bytes|                    |\n|            Location|file:/spark/sql/w...|                    |\n|       Serde Library|org.apache.hadoop...|                    |\n|         InputFormat|org.apache.hadoop...|                    |\n|        OutputFormat|org.apache.hadoop...|                    |\n+--------------------+--------------------+--------------------+\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546906_60838402",
      "id": "paragraph_1614134414307_1504412999",
      "dateCreated": "2021-03-13 22:29:06.906",
      "dateStarted": "2021-03-17 21:01:22.478",
      "dateFinished": "2021-03-17 21:01:22.915",
      "status": "FINISHED"
    },
    {
      "title": "Generate Columnar Statistics for our CoffeeCo Patrons",
      "text": "%sql\nANALYZE TABLE coffee_co_common.`customers` COMPUTE STATISTICS FOR COLUMNS id, first_name, last_name, email",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 21:02:02.741",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://zeppelin:4040/jobs/job?id\u003d3"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546906_145919680",
      "id": "paragraph_1614219841156_2067151231",
      "dateCreated": "2021-03-13 22:29:06.906",
      "dateStarted": "2021-03-17 21:02:02.754",
      "dateFinished": "2021-03-17 21:02:04.768",
      "status": "FINISHED"
    },
    {
      "title": "View Table Level Metadata and Statistics",
      "text": "%sql\nDESCRIBE EXTENDED coffee_co_common.`customers`",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 21:02:26.925",
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "col_name": "string",
                      "data_type": "string",
                      "comment": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TABLE",
            "data": "col_name\tdata_type\tcomment\nid\tint\tUnique identifier for our Customer.\ncreated\ttimestamp\ttimestamp when the account became active\nupdated\ttimestamp\ttimestamp when this record last changed\nfirst_name\tstring\tThe first name on the account\nlast_name\tstring\tThe last name on the account\nemail\tstring\tcustomers email on file. Unique Constraint. Not to be used for Marketing\n\t\t\n# Detailed Table Information\t\t\nDatabase\tcoffee_co_common\t\nTable\tcustomers\t\nOwner\tzeppelin\t\nCreated Time\tWed Mar 17 21:00:29 UTC 2021\t\nLast Access\tUNKNOWN\t\nCreated By\tSpark 3.1.1\t\nType\tMANAGED\t\nProvider\tparquet\t\nComment\tProduction Customers Data\t\nTable Properties\t[active\u003dtrue]\t\nStatistics\t1896 bytes, 8 rows\t\nLocation\tfile:/spark/sql/warehouse/common/customers\t\nSerde Library\torg.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe\t\nInputFormat\torg.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat\t\nOutputFormat\torg.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat\t\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546906_535286306",
      "id": "paragraph_1614133431449_1680772555",
      "dateCreated": "2021-03-13 22:29:06.906",
      "dateStarted": "2021-03-17 21:02:26.938",
      "dateFinished": "2021-03-17 21:02:27.097",
      "status": "FINISHED"
    },
    {
      "title": "View the Columnar Statistics for the email Column",
      "text": "%spark\nspark.sql(\"describe extended customers id\").show(truncate\u003dfalse)",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 21:02:33.374",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+--------------+----------+\n|info_name     |info_value|\n+--------------+----------+\n|col_name      |id        |\n|data_type     |int       |\n|comment       |NULL      |\n|min           |NULL      |\n|max           |NULL      |\n|num_nulls     |NULL      |\n|distinct_count|NULL      |\n|avg_col_len   |NULL      |\n|max_col_len   |NULL      |\n|histogram     |NULL      |\n+--------------+----------+\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546906_288988828",
      "id": "paragraph_1614220468329_216733012",
      "dateCreated": "2021-03-13 22:29:06.906",
      "dateStarted": "2021-03-17 21:02:33.395",
      "dateFinished": "2021-03-17 21:02:33.656",
      "status": "FINISHED"
    },
    {
      "text": "%sh\n\nls -l /spark/sql/warehouse/common/\n\n",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 21:02:44.693",
      "config": {
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sh",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "total 0\ndrwxr-xr-x 6 zeppelin root 192 Mar 17 21:00 customers\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546906_1789628150",
      "id": "paragraph_1614133550814_1372181408",
      "dateCreated": "2021-03-13 22:29:06.907",
      "dateStarted": "2021-03-17 21:02:44.715",
      "dateFinished": "2021-03-17 21:02:45.349",
      "status": "FINISHED"
    },
    {
      "title": "Removing Temp Views from the Spark SQL Catalog",
      "text": "%spark\nsparkSessionHive.catalog.dropTempView(\"customers\")",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 21:02:50.859",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mres16\u001b[0m: \u001b[1m\u001b[32mBoolean\u001b[0m \u003d true\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615766858889_366604295",
      "id": "paragraph_1615766858889_366604295",
      "dateCreated": "2021-03-15 00:07:38.889",
      "dateStarted": "2021-03-17 21:02:50.872",
      "dateFinished": "2021-03-17 21:02:51.103",
      "status": "FINISHED"
    },
    {
      "title": "Sanity Check: We did drop the temp view right",
      "text": "%spark\nsparkSessionHive.catalog.listTables().show",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 22:33:29.988",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+--------------+----------------+--------------------+---------+-----------+\n|          name|        database|         description|tableType|isTemporary|\n+--------------+----------------+--------------------+---------+-----------+\n|     customers|coffee_co_common|Production Custom...|  MANAGED|      false|\n|customers_temp|coffee_co_common|                null|  MANAGED|      false|\n|       unioned|coffee_co_common|                null|  MANAGED|      false|\n+--------------+----------------+--------------------+---------+-----------+\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615766602243_1407661345",
      "id": "paragraph_1615766602243_1407661345",
      "dateCreated": "2021-03-15 00:03:22.243",
      "dateStarted": "2021-03-17 22:33:30.006",
      "dateFinished": "2021-03-17 22:33:30.663",
      "status": "FINISHED"
    },
    {
      "text": "%md\n## Spark SQL Catalog: Caching, Uncaching and Refreshing Tables",
      "user": "anonymous",
      "dateUpdated": "2021-03-15 00:09:17.869",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eSpark SQL Catalog: Caching, Uncaching and Refreshing Tables\u003c/h2\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615766931976_1917949239",
      "id": "paragraph_1615766931976_1917949239",
      "dateCreated": "2021-03-15 00:08:51.977",
      "dateStarted": "2021-03-15 00:09:17.869",
      "dateFinished": "2021-03-15 00:09:17.877",
      "status": "FINISHED"
    },
    {
      "title": "Check that a Table Exists",
      "text": "%spark\nval dbName \u003d \"coffee_co_common\"\nval tableName \u003d \"customers\"\n\nval tableExists \u003d sparkSessionHive.catalog.tableExists(dbName, tableName)\n",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 21:03:00.792",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mdbName\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d coffee_co_common\n\u001b[1m\u001b[34mtableName\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d customers\n\u001b[1m\u001b[34mtableExists\u001b[0m: \u001b[1m\u001b[32mBoolean\u001b[0m \u003d true\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546907_1943049197",
      "id": "paragraph_1614191774935_333180712",
      "dateCreated": "2021-03-13 22:29:06.907",
      "dateStarted": "2021-03-17 21:03:00.805",
      "dateFinished": "2021-03-17 21:03:01.040",
      "status": "FINISHED"
    },
    {
      "title": "Cache a Table in Spark Memory",
      "text": "%spark\nval tableName \u003d \"customers\"\nif (!sparkSessionHive.catalog.isCached(tableName)) {\n  sparkSessionHive.catalog.cacheTable(tableName)    \n}\nval isCached \u003d sparkSessionHive.catalog.isCached(tableName)",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 22:33:47.721",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mtableName\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d customers\n\u001b[1m\u001b[34misCached\u001b[0m: \u001b[1m\u001b[32mBoolean\u001b[0m \u003d true\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546907_2050849533",
      "id": "paragraph_1614196291105_1977788944",
      "dateCreated": "2021-03-13 22:29:06.907",
      "dateStarted": "2021-03-17 22:33:47.743",
      "dateFinished": "2021-03-17 22:33:48.270",
      "status": "FINISHED"
    },
    {
      "title": "Force the Cache using Show",
      "text": "%spark\nval tableName \u003d \"customers\"\n\nsparkSessionHive.table(tableName).head\n\n/*spark.table(tableName)\n  .select($\"first_name\", $\"email\")\n  .show*/",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 22:33:50.947",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mtableName\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d customers\n\u001b[1m\u001b[34mres8\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Row\u001b[0m \u003d [1,2021-02-16 00:16:06.0,2021-03-13 21:10:28.0,Scott,Haines,scott@coffeeco.com]\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://zeppelin:4040/jobs/job?id\u003d1"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615769186880_1466680857",
      "id": "paragraph_1615769186880_1466680857",
      "dateCreated": "2021-03-15 00:46:26.880",
      "dateStarted": "2021-03-17 22:33:50.962",
      "dateFinished": "2021-03-17 22:33:52.152",
      "status": "FINISHED"
    },
    {
      "title": "Remove a Cached Table from Spark Memory",
      "text": "%spark\nval tableName \u003d \"customers\"\nsparkSessionHive.catalog.uncacheTable(tableName)",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 22:33:55.936",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mtableName\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d customers\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546907_982272110",
      "id": "paragraph_1614196564820_1192461591",
      "dateCreated": "2021-03-13 22:29:06.907",
      "dateStarted": "2021-03-17 22:33:55.950",
      "dateFinished": "2021-03-17 22:33:56.294",
      "status": "FINISHED"
    },
    {
      "title": "Clear All Cached Tables",
      "text": "%spark\nspark.catalog.clearCache",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 22:33:58.894",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546907_698677117",
      "id": "paragraph_1614196588567_1685464875",
      "dateCreated": "2021-03-13 22:29:06.907",
      "dateStarted": "2021-03-17 22:33:58.910",
      "dateFinished": "2021-03-17 22:33:59.098",
      "status": "FINISHED"
    },
    {
      "text": "%md\n## Testing Automatic Cache Refresh in Spark\nThe following section splits up the process of copying the data from our `customers` table into a new temporary table, so we can experiment witout breaking our source of truth table.\n\n1. Copys the contents of the `customers` table into a new managed table called `customers_temp`\n2. Reads from this new managed table `customers_temp` into a reference variable called `tableCopy`, and then caches the table.\n3. We call `tableCopy.head` in order to cache off the table in local spark memory\n4. We purposefull `union` tableCopy with itself in order to duplicate the data\n5. Then we write out into yet another managed table named `union`\n6. Now we are free to `overwrite` the initial `customers_temp` table without Spark informing us that we are trying to overwrite a table we are currently reading from. (Yeah it is that smart)\n7. We trick the saftey check and now have our `duplicates` loaded in `customers_temp`.\n8. Interestingly enough, if you look at the Storage Tab in the Spark UI (http://localhost:4040/storage/) you will see that Spark has purged its own cache since they are no longer accurate.",
      "user": "anonymous",
      "dateUpdated": "2021-03-15 02:00:52.919",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eTesting Automatic Cache Refresh in Spark\u003c/h2\u003e\n\u003cp\u003eThe following section splits up the process of copying the data from our \u003ccode\u003ecustomers\u003c/code\u003e table into a new temporary table, so we can experiment witout breaking our source of truth table.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eCopys the contents of the \u003ccode\u003ecustomers\u003c/code\u003e table into a new managed table called \u003ccode\u003ecustomers_temp\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eReads from this new managed table \u003ccode\u003ecustomers_temp\u003c/code\u003e into a reference variable called \u003ccode\u003etableCopy\u003c/code\u003e, and then caches the table.\u003c/li\u003e\n\u003cli\u003eWe call \u003ccode\u003etableCopy.head\u003c/code\u003e in order to cache off the table in local spark memory\u003c/li\u003e\n\u003cli\u003eWe purposefull \u003ccode\u003eunion\u003c/code\u003e tableCopy with itself in order to duplicate the data\u003c/li\u003e\n\u003cli\u003eThen we write out into yet another managed table named \u003ccode\u003eunion\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eNow we are free to \u003ccode\u003eoverwrite\u003c/code\u003e the initial \u003ccode\u003ecustomers_temp\u003c/code\u003e table without Spark informing us that we are trying to overwrite a table we are currently reading from. (Yeah it is that smart)\u003c/li\u003e\n\u003cli\u003eWe trick the saftey check and now have our \u003ccode\u003eduplicates\u003c/code\u003e loaded in \u003ccode\u003ecustomers_temp\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eInterestingly enough, if you look at the Storage Tab in the Spark UI (\u003ca href\u003d\"http://localhost:4040/storage/\"\u003ehttp://localhost:4040/storage/\u003c/a\u003e) you will see that Spark has purged its own cache since they are no longer accurate.\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615773294860_779243069",
      "id": "paragraph_1615773294860_779243069",
      "dateCreated": "2021-03-15 01:54:54.860",
      "dateStarted": "2021-03-15 02:00:52.919",
      "dateFinished": "2021-03-15 02:00:52.938",
      "status": "FINISHED"
    },
    {
      "title": "Refreshing our Cache",
      "text": "%spark\nval dbName \u003d \"coffee_co_common\"\nval upstreamTableName \u003d \"customers\"\nval tempTableName \u003d \"customers_temp\"\n\n// set the db context\n\nsparkSessionHive\n  .catalog\n  .setCurrentDatabase(dbName)\n\n// copy our upstream table\n\nsparkSessionHive\n  .table(upstreamTableName)\n  .write\n  .mode(\"overwrite\")\n  .partitionBy(\"email\")\n  .saveAsTable(tempTableName)\n\n// now we have a table that we can mess around with\nval tableCopy \u003d sparkSessionHive.table(tempTableName)\nsparkSessionHive.catalog.cacheTable(tempTableName)\n\n// force the cache\ntableCopy.head\n\n",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 23:16:15.016",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "org.apache.spark.sql.AnalysisException: org.apache.hadoop.hive.ql.metadata.HiveException: MetaException(message:One or more instances could not be deleted)\n  at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:112)\n  at org.apache.spark.sql.hive.HiveExternalCatalog.dropTable(HiveExternalCatalog.scala:517)\n  at org.apache.spark.sql.catalyst.catalog.ExternalCatalogWithListener.dropTable(ExternalCatalogWithListener.scala:104)\n  at org.apache.spark.sql.catalyst.catalog.SessionCatalog.dropTable(SessionCatalog.scala:778)\n  at org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:726)\n  at org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:626)\n  ... 46 elided\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: MetaException(message:One or more instances could not be deleted)\n  at org.apache.hadoop.hive.ql.metadata.Hive.dropTable(Hive.java:1200)\n  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n  at java.lang.reflect.Method.invoke(Method.java:498)\n  at org.apache.spark.sql.hive.client.Shim_v0_14.dropTable(HiveShim.scala:1015)\n  at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$dropTable$1(HiveClientImpl.scala:551)\n  at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n  at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:291)\n  at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n  at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n  at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n  at org.apache.spark.sql.hive.client.HiveClientImpl.dropTable(HiveClientImpl.scala:551)\n  at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$dropTable$1(HiveExternalCatalog.scala:519)\n  at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n  at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n  ... 51 more\nCaused by: org.apache.hadoop.hive.metastore.api.MetaException: One or more instances could not be deleted\n  at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:211)\n  at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n  at com.sun.proxy.$Proxy21.drop_table_with_environment_context(Unknown Source)\n  at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.drop_table_with_environment_context(HiveMetaStoreClient.java:2411)\n  at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.drop_table_with_environment_context(SessionHiveMetaStoreClient.java:114)\n  at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropTable(HiveMetaStoreClient.java:1095)\n  at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.dropTable(HiveMetaStoreClient.java:1031)\n  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n  at java.lang.reflect.Method.invoke(Method.java:498)\n  at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:173)\n  at com.sun.proxy.$Proxy22.dropTable(Unknown Source)\n  at org.apache.hadoop.hive.ql.metadata.Hive.dropTable(Hive.java:1194)\n  ... 66 more\nCaused by: javax.jdo.JDOUserException: One or more instances could not be deleted\n  at org.datanucleus.api.jdo.JDOPersistenceManager.deletePersistentAll(JDOPersistenceManager.java:848)\n  at org.apache.hadoop.hive.metastore.ObjectStore.dropTable(ObjectStore.java:1065)\n  at sun.reflect.GeneratedMethodAccessor37.invoke(Unknown Source)\n  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n  at java.lang.reflect.Method.invoke(Method.java:498)\n  at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:101)\n  at com.sun.proxy.$Proxy20.dropTable(Unknown Source)\n  at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_table_core(HiveMetaStore.java:1698)\n  at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.drop_table_with_environment_context(HiveMetaStore.java:1925)\n  at sun.reflect.GeneratedMethodAccessor33.invoke(Unknown Source)\n  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n  at java.lang.reflect.Method.invoke(Method.java:498)\n  at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n  ... 79 more\nCaused by: org.datanucleus.exceptions.NucleusDataStoreException: Fetch of object \"org.apache.hadoop.hive.metastore.model.MTablePrivilege@769c9827\" using statement \"SELECT `B0`.`CREATE_TIME`,`B0`.`LAST_ACCESS_TIME`,`B0`.`OWNER`,`B0`.`RETENTION`,`B0`.`IS_REWRITE_ENABLED`,`B0`.`TBL_NAME`,`B0`.`TBL_TYPE`,`B0`.`TBL_ID` FROM `TBL_PRIVS` `A0` LEFT OUTER JOIN `TBLS` `B0` ON `A0`.`TBL_ID` \u003d `B0`.`TBL_ID` WHERE `A0`.`TBL_GRANT_ID` \u003d ?\" failed : DELETE command denied to user \u0027dataeng\u0027@\u0027172.18.0.3\u0027 for table \u0027tbl_privs\u0027\n  at org.datanucleus.store.rdbms.request.FetchRequest.execute(FetchRequest.java:397)\n  at org.datanucleus.store.rdbms.RDBMSPersistenceHandler.fetchObject(RDBMSPersistenceHandler.java:319)\n  at org.datanucleus.state.AbstractStateManager.loadFieldsFromDatastore(AbstractStateManager.java:1147)\n  at org.datanucleus.state.StateManagerImpl.loadSpecifiedFields(StateManagerImpl.java:2564)\n  at org.datanucleus.state.StateManagerImpl.loadField(StateManagerImpl.java:2581)\n  at org.datanucleus.store.rdbms.mapping.java.PersistableMapping.preDelete(PersistableMapping.java:924)\n  at org.datanucleus.store.rdbms.request.DeleteRequest.execute(DeleteRequest.java:193)\n  at org.datanucleus.store.rdbms.RDBMSPersistenceHandler.deleteObjectFromTable(RDBMSPersistenceHandler.java:499)\n  at org.datanucleus.store.rdbms.RDBMSPersistenceHandler.deleteObject(RDBMSPersistenceHandler.java:470)\n  at org.datanucleus.state.AbstractStateManager.internalDeletePersistent(AbstractStateManager.java:832)\n  at org.datanucleus.state.StateManagerImpl.deletePersistent(StateManagerImpl.java:4244)\n  at org.datanucleus.ExecutionContextImpl.deleteObjectInternal(ExecutionContextImpl.java:2396)\n  at org.datanucleus.ExecutionContextImpl.deleteObjectWork(ExecutionContextImpl.java:2318)\n  at org.datanucleus.ExecutionContextImpl.deleteObjects(ExecutionContextImpl.java:2210)\n  at org.datanucleus.ExecutionContextThreadedImpl.deleteObjects(ExecutionContextThreadedImpl.java:259)\n  at org.datanucleus.api.jdo.JDOPersistenceManager.deletePersistentAll(JDOPersistenceManager.java:843)\n  ... 91 more\nCaused by: java.sql.BatchUpdateException: DELETE command denied to user \u0027dataeng\u0027@\u0027172.18.0.3\u0027 for table \u0027tbl_privs\u0027\n  at sun.reflect.GeneratedConstructorAccessor87.newInstance(Unknown Source)\n  at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n  at java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n  at com.mysql.cj.util.Util.handleNewInstance(Util.java:192)\n  at com.mysql.cj.util.Util.getInstance(Util.java:167)\n  at com.mysql.cj.util.Util.getInstance(Util.java:174)\n  at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)\n  at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:853)\n  at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:435)\n  at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:794)\n  at com.jolbox.bonecp.StatementHandle.executeBatch(StatementHandle.java:424)\n  at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeBatch(ParamLoggingPreparedStatement.java:366)\n  at org.datanucleus.store.rdbms.SQLController.processConnectionStatement(SQLController.java:676)\n  at org.datanucleus.store.rdbms.SQLController.getStatementForQuery(SQLController.java:319)\n  at org.datanucleus.store.rdbms.SQLController.getStatementForQuery(SQLController.java:295)\n  at org.datanucleus.store.rdbms.request.FetchRequest.execute(FetchRequest.java:318)\n  ... 106 more\nCaused by: java.sql.SQLSyntaxErrorException: DELETE command denied to user \u0027dataeng\u0027@\u0027172.18.0.3\u0027 for table \u0027tbl_privs\u0027\n  at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:120)\n  at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)\n  at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)\n  at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1092)\n  at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:832)\n  ... 114 more\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615770969139_2137540136",
      "id": "paragraph_1615770969139_2137540136",
      "dateCreated": "2021-03-15 01:16:09.139",
      "dateStarted": "2021-03-17 23:16:15.031",
      "dateFinished": "2021-03-17 23:16:35.983",
      "status": "ERROR"
    },
    {
      "title": "Purposefully Duplicating Rows using Union",
      "text": "%spark\n\nval unionTable \u003d tableCopy.union(tableCopy)\nunionTable.cache()\nunionTable.show()\nunionTable.write.mode(\"overwrite\").saveAsTable(\"unioned\")\n",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 21:36:44.226",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+---+-------------------+-------------------+----------+---------+--------------------+\n| id|            created|            updated|first_name|last_name|               email|\n+---+-------------------+-------------------+----------+---------+--------------------+\n|  6|2021-02-21 23:00:00|2021-03-13 21:10:28|   Marshal|   Haines|   paws@coffeeco.com|\n|  8|2021-02-24 09:00:00|2021-03-13 21:10:28|    Clover|   Haines|    pup@coffeeco.com|\n|  7|2021-02-24 09:00:00|2021-03-13 21:10:28|    Willow|   Haines| willow@coffeeco.com|\n|  4|2021-02-21 21:00:00|2021-03-13 21:10:28|     Penny|   Haines|  penny@coffeeco.com|\n|  1|2021-02-16 00:16:06|2021-03-13 21:10:28|     Scott|   Haines|  scott@coffeeco.com|\n|  3|2021-02-16 00:16:06|2021-03-13 21:10:28|      Milo|   Haines|mhaines@coffeeco.com|\n|  5|2021-02-21 22:00:00|2021-03-13 21:10:28|     Cloud|     Fast| cloud.fast@acme.com|\n|  2|2021-02-16 00:16:06|2021-03-13 21:10:28|      John|     Hamm|  john.hamm@acme.com|\n|  6|2021-02-21 23:00:00|2021-03-13 21:10:28|   Marshal|   Haines|   paws@coffeeco.com|\n|  8|2021-02-24 09:00:00|2021-03-13 21:10:28|    Clover|   Haines|    pup@coffeeco.com|\n|  7|2021-02-24 09:00:00|2021-03-13 21:10:28|    Willow|   Haines| willow@coffeeco.com|\n|  4|2021-02-21 21:00:00|2021-03-13 21:10:28|     Penny|   Haines|  penny@coffeeco.com|\n|  1|2021-02-16 00:16:06|2021-03-13 21:10:28|     Scott|   Haines|  scott@coffeeco.com|\n|  3|2021-02-16 00:16:06|2021-03-13 21:10:28|      Milo|   Haines|mhaines@coffeeco.com|\n|  5|2021-02-21 22:00:00|2021-03-13 21:10:28|     Cloud|     Fast| cloud.fast@acme.com|\n|  2|2021-02-16 00:16:06|2021-03-13 21:10:28|      John|     Hamm|  john.hamm@acme.com|\n+---+-------------------+-------------------+----------+---------+--------------------+\n\n\u001b[1m\u001b[34munionTable\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\u001b[0m \u003d [id: int, created: timestamp ... 4 more fields]\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://zeppelin:4040/jobs/job?id\u003d6"
            },
            {
              "jobUrl": "http://zeppelin:4040/jobs/job?id\u003d7"
            },
            {
              "jobUrl": "http://zeppelin:4040/jobs/job?id\u003d8"
            },
            {
              "jobUrl": "http://zeppelin:4040/jobs/job?id\u003d9"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615771813317_1262968975",
      "id": "paragraph_1615771813317_1262968975",
      "dateCreated": "2021-03-15 01:30:13.318",
      "dateStarted": "2021-03-17 21:36:44.243",
      "dateFinished": "2021-03-17 21:36:45.650",
      "status": "FINISHED"
    },
    {
      "text": "%md\n### Check the Spark Storage UI\nYou should see at least Two items in your Cache.\n1. The customers_temp is stored in memory\n2. The non-table cached dataframe `unionTable.cache()`",
      "user": "anonymous",
      "dateUpdated": "2021-03-15 02:09:56.482",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eCheck the Spark Storage UI\u003c/h3\u003e\n\u003cp\u003eYou should see at least Two items in your Cache.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eThe customers_temp is stored in memory\u003c/li\u003e\n\u003cli\u003eThe non-table cached dataframe \u003ccode\u003eunionTable.cache()\u003c/code\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615774130257_2007166093",
      "id": "paragraph_1615774130257_2007166093",
      "dateCreated": "2021-03-15 02:08:50.257",
      "dateStarted": "2021-03-15 02:09:56.482",
      "dateFinished": "2021-03-15 02:09:56.492",
      "status": "FINISHED"
    },
    {
      "title": "Overwrite the customers_temp table",
      "text": "%spark\nsparkSessionHive\n  .table(\"unioned\")\n  .write\n  .mode(\"overwrite\")\n  .saveAsTable(tempTableName)",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 21:36:52.817",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://zeppelin:4040/jobs/job?id\u003d10"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615772479783_1053986099",
      "id": "paragraph_1615772479783_1053986099",
      "dateCreated": "2021-03-15 01:41:19.783",
      "dateStarted": "2021-03-17 21:36:52.828",
      "dateFinished": "2021-03-17 21:36:53.913",
      "status": "FINISHED"
    },
    {
      "text": "%md\n### Now you will have no more cache.\nSpark has now automatically managed the caches you created. Go ahead and check http://localhost:4040/storage/ to see for yourself.",
      "user": "anonymous",
      "dateUpdated": "2021-03-15 02:08:42.345",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eNow you will have no more cache.\u003c/h3\u003e\n\u003cp\u003eSpark has now automatically managed the caches you created. Go ahead and check \u003ca href\u003d\"http://localhost:4040/storage/\"\u003ehttp://localhost:4040/storage/\u003c/a\u003e to see for yourself.\u003c/p\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615774078953_617192682",
      "id": "paragraph_1615774078953_617192682",
      "dateCreated": "2021-03-15 02:07:58.953",
      "dateStarted": "2021-03-15 02:08:42.346",
      "dateFinished": "2021-03-15 02:08:42.356",
      "status": "FINISHED"
    },
    {
      "title": "Refresh the Metadata and Cached data of a Table",
      "text": "%spark\nsparkSessionHive.catalog.refreshTable(tempTableName)",
      "user": "anonymous",
      "dateUpdated": "2021-03-15 02:11:00.273",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615772190998_1314145125",
      "id": "paragraph_1615772190998_1314145125",
      "dateCreated": "2021-03-15 01:36:30.998",
      "dateStarted": "2021-03-15 02:11:00.290",
      "dateFinished": "2021-03-15 02:11:00.624",
      "status": "FINISHED"
    },
    {
      "title": "Viewing the Duplicated Data in customers_temp",
      "text": "%spark\nsparkSessionHive.sql(\"select * from customers_temp limit 100\").show(100)",
      "user": "anonymous",
      "dateUpdated": "2021-03-15 02:11:48.601",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+---+-------------------+-------------------+----------+---------+--------------------+\n| id|            created|            updated|first_name|last_name|               email|\n+---+-------------------+-------------------+----------+---------+--------------------+\n|  1|2021-02-16 00:16:06|2021-03-13 21:10:28|     Scott|   Haines|  scott@coffeeco.com|\n|  3|2021-02-16 00:16:06|2021-03-13 21:10:28|      Milo|   Haines|mhaines@coffeeco.com|\n|  1|2021-02-16 00:16:06|2021-03-13 21:10:28|     Scott|   Haines|  scott@coffeeco.com|\n|  3|2021-02-16 00:16:06|2021-03-13 21:10:28|      Milo|   Haines|mhaines@coffeeco.com|\n|  7|2021-02-24 09:00:00|2021-03-13 21:10:28|    Willow|   Haines| willow@coffeeco.com|\n|  4|2021-02-21 21:00:00|2021-03-13 21:10:28|     Penny|   Haines|  penny@coffeeco.com|\n|  7|2021-02-24 09:00:00|2021-03-13 21:10:28|    Willow|   Haines| willow@coffeeco.com|\n|  4|2021-02-21 21:00:00|2021-03-13 21:10:28|     Penny|   Haines|  penny@coffeeco.com|\n|  6|2021-02-21 23:00:00|2021-03-13 21:10:28|   Marshal|   Haines|   paws@coffeeco.com|\n|  8|2021-02-24 09:00:00|2021-03-13 21:10:28|    Clover|   Haines|    pup@coffeeco.com|\n|  6|2021-02-21 23:00:00|2021-03-13 21:10:28|   Marshal|   Haines|   paws@coffeeco.com|\n|  8|2021-02-24 09:00:00|2021-03-13 21:10:28|    Clover|   Haines|    pup@coffeeco.com|\n|  5|2021-02-21 22:00:00|2021-03-13 21:10:28|     Cloud|     Fast| cloud.fast@acme.com|\n|  2|2021-02-16 00:16:06|2021-03-13 21:10:28|      John|     Hamm|  john.hamm@acme.com|\n|  5|2021-02-21 22:00:00|2021-03-13 21:10:28|     Cloud|     Fast| cloud.fast@acme.com|\n|  2|2021-02-16 00:16:06|2021-03-13 21:10:28|      John|     Hamm|  john.hamm@acme.com|\n+---+-------------------+-------------------+----------+---------+--------------------+\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://zeppelin:4040/jobs/job?id\u003d117"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615771683288_1822681402",
      "id": "paragraph_1615771683288_1822681402",
      "dateCreated": "2021-03-15 01:28:03.288",
      "dateStarted": "2021-03-15 02:11:48.616",
      "dateFinished": "2021-03-15 02:11:49.075",
      "status": "FINISHED"
    },
    {
      "text": "%spark\nsparkSessionHive.catalog.clearCache",
      "user": "anonymous",
      "dateUpdated": "2021-03-15 02:11:11.810",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615772502530_665522115",
      "id": "paragraph_1615772502530_665522115",
      "dateCreated": "2021-03-15 01:41:42.530",
      "dateStarted": "2021-03-15 02:11:11.827",
      "dateFinished": "2021-03-15 02:11:12.034",
      "status": "FINISHED"
    },
    {
      "text": "%md\n## Removing Tables\nIf you want to remove a table from the hive metastore. All you have to do is use the DROP TABLE command. This will remove everything from the warehouse so **BE CAREFUL**. Always create a backup of a Table before doing this in the real world. There is no *undo*!\n\n**Spark SQLContext**\n~~~\nspark.sql(\"DROP TABLE customers_temp\")\n~~~\n~~~\nspark.sql(\"DROP TABLE unioned\")\n~~~\n\n**Spark SQL: Interpreted**\n~~~\nspark.sql(\"drop table if exists customers_temp\").show\n~~~\n\n**Spark SQL: Via Catalyst Session Catalog**\n~~~\nimport org.apache.spark.sql.catalyst.TableIdentifier\n\nval sessionCatalog \u003d spark.sessionState.catalog\nval tableName \u003d \"customers_temp\"\nval tableId \u003d TableIdentifier(tableName)\nval warehousePath \u003d sessionCatalog.defaultTablePath(tableId)\n// drop the table using the DSL\nsessionCatalog.dropTable(tableId)\n~~~\n",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 20:47:28.671",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eRemoving Tables\u003c/h2\u003e\n\u003cp\u003eIf you want to remove a table from the hive metastore. All you have to do is use the DROP TABLE command. This will remove everything from the warehouse so \u003cstrong\u003eBE CAREFUL\u003c/strong\u003e. Always create a backup of a Table before doing this in the real world. There is no \u003cem\u003eundo\u003c/em\u003e!\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSpark SQLContext\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003espark.sql(\u0026quot;DROP TABLE customers_temp\u0026quot;)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003espark.sql(\u0026quot;DROP TABLE unioned\u0026quot;)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSpark SQL: Interpreted\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003espark.sql(\u0026quot;drop table if exists customers_temp\u0026quot;).show\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSpark SQL: Via Catalyst Session Catalog\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport org.apache.spark.sql.catalyst.TableIdentifier\n\nval sessionCatalog \u003d spark.sessionState.catalog\nval tableName \u003d \u0026quot;customers_temp\u0026quot;\nval tableId \u003d TableIdentifier(tableName)\nval warehousePath \u003d sessionCatalog.defaultTablePath(tableId)\n// drop the table using the DSL\nsessionCatalog.dropTable(tableId)\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546907_285707128",
      "id": "paragraph_1614196170330_548164959",
      "dateCreated": "2021-03-13 22:29:06.907",
      "dateStarted": "2021-03-17 20:47:28.672",
      "dateFinished": "2021-03-17 20:47:29.810",
      "status": "FINISHED"
    },
    {
      "title": "Conditionally Drop a Table",
      "text": "%sql\nDROP TABLE IF EXISTS customers_temp;\nDROP TABLE IF EXISTS unioned;",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 20:47:52.353",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/sql",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615774456326_1636824413",
      "id": "paragraph_1615774456326_1636824413",
      "dateCreated": "2021-03-15 02:14:16.326",
      "dateStarted": "2021-03-15 02:20:06.345",
      "dateFinished": "2021-03-15 02:20:06.620",
      "status": "FINISHED"
    },
    {
      "title": "Using Catalyst to Locate and Remove a Table",
      "text": "%spark\nimport org.apache.spark.sql.catalyst.TableIdentifier\n\nval catalog \u003d sparkSessionHive.sessionState.catalog\nval tableName \u003d \"customers_temp\"\nval tableId \u003d TableIdentifier(tableName)\nval warehousePath \u003d catalog.defaultTablePath(tableId)\n\ncatalog\n  .dropTable(\n      tableId,\n      ignoreIfNotExists\u003dtrue,\n      purge\u003dtrue\n  )\n",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 21:36:14.144",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import org.apache.spark.sql.catalyst.TableIdentifier\n\u001b[1m\u001b[34mcatalog\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.catalyst.catalog.SessionCatalog\u001b[0m \u003d org.apache.spark.sql.hive.HiveSessionCatalog@55b14230\n\u001b[1m\u001b[34mtableName\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d customers_temp\n\u001b[1m\u001b[34mtableId\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.catalyst.TableIdentifier\u001b[0m \u003d `customers_temp`\n\u001b[1m\u001b[34mwarehousePath\u001b[0m: \u001b[1m\u001b[32mjava.net.URI\u001b[0m \u003d file:/spark/sql/warehouse/common/customers_temp\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615674546907_874100849",
      "id": "paragraph_1614218526056_321018203",
      "dateCreated": "2021-03-13 22:29:06.907",
      "dateStarted": "2021-03-17 21:36:14.156",
      "dateFinished": "2021-03-17 21:36:14.415",
      "status": "FINISHED"
    },
    {
      "text": "%spark\n",
      "user": "anonymous",
      "dateUpdated": "2021-03-17 20:48:43.858",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1616014123857_1405518586",
      "id": "paragraph_1616014123857_1405518586",
      "dateCreated": "2021-03-17 20:48:43.857",
      "status": "READY"
    }
  ],
  "name": "6_2_SparkSQLCatalog",
  "id": "2G11JZSJP",
  "defaultInterpreterGroup": "spark",
  "version": "0.9.0-preview2",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}